{
    "is_PEFT": true,
    "metrics": ["bertscore", "bleu", "rouge", "perplexity"],
    "max_input_length": 512,
    "max_output_length": 512,
    "padding": "max_length",
    "truncation": "from_end",
    "data_official": true,
    "seed": 1234,
    "PEFT_model_dir": "output/0109/gpt2/checkpoint-300",
    "logging_dir": "logs/gpt2",
    "GenerateConfig": {
        "do_sample": true,
        "top_k": 30,
        "top_p": 0.9,
        "temperature": 0.7,
        "repetition_penalty": 1.03,
        "max_length": 64
    }
}